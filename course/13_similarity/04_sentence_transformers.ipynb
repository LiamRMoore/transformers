{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings With Sentence-Transformers\n",
    "\n",
    "We've worked through creating our embeddings using the `transformers` library - and at times it can be quite involved. Now, it's important to understand the steps, but we can make life easier by using the `sentence-transformers` library.\n",
    "\n",
    "We'll work through the same process - but using `sentence-transformers` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"Standing on one's head at job interviews forms a lasting impression.\",\n",
    "    \"It took him a month to finish the meal.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]\n",
    "\n",
    "# thanks to https://randomwordgenerator.com/sentence.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[1m^2.2.2\u001b[0m for \u001b[36msentence-transformers\u001b[0m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[0m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(121.0s)\u001b[0m[34mResolving dependencies...\u001b[0m \u001b[39;2m(67.9s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(73.3s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(79.0s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(94.7s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(106.9s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(111.9s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[39;2m(117.2s)\u001b[0m\n",
      "\n",
      "  \u001b[31;1mSolverProblemError\u001b[0m\n",
      "\n",
      "  \u001b[1mBecause no versions of sentence-transformers match >2.2.2,<3.0.0\n",
      "   and sentence-transformers (2.2.2) depends on transformers (>=4.6.0,<5.0.0), sentence-transformers (>=2.2.2,<3.0.0) requires transformers (>=4.6.0,<5.0.0).\n",
      "  And because farm (0.6.2) depends on transformers (4.1.1), sentence-transformers (>=2.2.2,<3.0.0) is incompatible with farm (0.6.2).\n",
      "  And because farm-haystack (0.7.0) depends on farm (0.6.2)\n",
      "   and no versions of farm-haystack match >0.7.0,<0.8.0, sentence-transformers (>=2.2.2,<3.0.0) is incompatible with farm-haystack (>=0.7.0,<0.8.0).\n",
      "  So, because dev depends on both farm-haystack (^0.7.0) and sentence-transformers (^2.2.2), version solving failed.\u001b[0m\n",
      "\n",
      "  at \u001b[32m/usr/app/.pyenv/versions/3.7.9/lib/python3.7/site-packages/poetry/puzzle/solver.py\u001b[0m:\u001b[1m241\u001b[0m in \u001b[36m_solve\u001b[0m\n",
      "      \u001b[39;2m237\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39m            packages \u001b[0m\u001b[39;2m= \u001b[0m\u001b[39mresult\u001b[0m\u001b[39;2m.\u001b[0m\u001b[39mpackages\u001b[0m\n",
      "      \u001b[39;2m238\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39m        \u001b[0m\u001b[35;1mexcept \u001b[0m\u001b[39mOverrideNeeded \u001b[0m\u001b[35;1mas \u001b[0m\u001b[39me\u001b[0m\u001b[39;2m:\u001b[0m\n",
      "      \u001b[39;2m239\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39m            \u001b[0m\u001b[35;1mreturn \u001b[0m\u001b[39;1mself\u001b[0m\u001b[39;2m.\u001b[0m\u001b[39msolve_in_compatibility_mode\u001b[0m\u001b[39;2m(\u001b[0m\u001b[39me\u001b[0m\u001b[39;2m.\u001b[0m\u001b[39moverrides\u001b[0m\u001b[39;2m, \u001b[0m\u001b[39muse_latest\u001b[0m\u001b[39;2m=\u001b[0m\u001b[39muse_latest\u001b[0m\u001b[39;2m)\u001b[0m\n",
      "      \u001b[39;2m240\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39;2m        \u001b[0m\u001b[35;1mexcept \u001b[0m\u001b[39mSolveFailure \u001b[0m\u001b[35;1mas \u001b[0m\u001b[39me\u001b[0m\u001b[39;2m:\u001b[0m\n",
      "    \u001b[31;1m→\u001b[0m \u001b[39;1m241\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39m            \u001b[0m\u001b[35;1mraise \u001b[0m\u001b[39mSolverProblemError\u001b[0m\u001b[39;2m(\u001b[0m\u001b[39me\u001b[0m\u001b[39;2m)\u001b[0m\n",
      "      \u001b[39;2m242\u001b[0m\u001b[39;2m│\u001b[0m \n",
      "      \u001b[39;2m243\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39m        results \u001b[0m\u001b[39;2m= \u001b[0m\u001b[39;1mdict\u001b[0m\u001b[39;2m(\u001b[0m\n",
      "      \u001b[39;2m244\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39m            depth_first_search\u001b[0m\u001b[39;2m(\u001b[0m\n",
      "      \u001b[39;2m245\u001b[0m\u001b[39;2m│\u001b[0m \u001b[39m                PackageNode\u001b[0m\u001b[39;2m(\u001b[0m\u001b[39;1mself\u001b[0m\u001b[39;2m.\u001b[0m\u001b[39m_package\u001b[0m\u001b[39;2m, \u001b[0m\u001b[39mpackages\u001b[0m\u001b[39;2m), \u001b[0m\u001b[39maggregate_package_nodes\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!poetry add sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_267/1856214565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-nli-mean-tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07464128,  0.8635731 ,  0.18004653, ...,  0.7732613 ,\n",
       "         1.7246002 , -0.18037328],\n",
       "       [-0.37150592,  0.97317815,  1.0839957 , ..., -0.25496134,\n",
       "        -0.275705  ,  0.03565905],\n",
       "       [-0.5025152 ,  0.7944973 , -0.12324826, ...,  0.14401469,\n",
       "         0.97013956, -0.17904879],\n",
       "       [-0.01328272,  0.9773259 ,  1.451448  , ..., -0.8458191 ,\n",
       "        -1.4004992 , -0.41184014],\n",
       "       [-0.20161639,  0.05962702,  0.86030865, ..., -0.00991616,\n",
       "         0.8431719 , -0.08434674],\n",
       "       [-0.21294485,  1.0176604 , -0.88306004, ...,  0.7370991 ,\n",
       "         0.19437043, -0.30156055]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And no we have our sentence embeddings - a much quicker approach. We then compare just as we did before using cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate cosine similarity for sentence `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33088642, 0.7218851 , 0.17474297, 0.44715378, 0.55473834]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These similarities translate to almost the exact same values as we calculated before:\n",
    "\n",
    "| Index | Sentence | Similarity (before) | New similarity |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\" | 0.3309 | 0.3309 |\n",
    "| 2 | \"The person box was packed with jelly many dozens of months later.\" | 0.7219 | 0.7219 |\n",
    "| 3 | \"Standing on one's head at job interviews forms a lasting impression.\" | 0.1748 | 0.174**7** |\n",
    "| 4 | \"It took him a month to finish the meal.\" | 0.4471 | 0.447**2** |\n",
    "| 5 | \"He found a leprechaun in his walnut shell.\" | 0.5548 | 0.554**7** |\n",
    "\n",
    "So, using `sentence-transformers` can make life much easier. But either option produces the same outcome."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
